{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Change these paths\n",
    "VAL_IMG_PATH = os.path.join(\"/Users/work/data/object_detection/WIDER/WIDER_val/images\", '*', '*.jpg')\n",
    "TRAIN_IMG_PATH = os.path.join(\"/Users/work/data/object_detection/WIDER/WIDER_train/images\", '*', '*.jpg')\n",
    "\n",
    "def int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(image_path):\n",
    "    for img_filename in glob(image_path):\n",
    "        yield img_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_files = list(get_images(VAL_IMG_PATH))\n",
    "train_img_files = list(get_images(TRAIN_IMG_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    img = Image.open(filename)\n",
    "    width = img.width\n",
    "    height = img.height\n",
    "    with open(filename, 'rb') as f:\n",
    "        return f.read(), width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = list(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3226"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13--Interview'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path(img_files[0])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bbox_data(bbox_def_file):\n",
    "    bbox_by_image = {}\n",
    "    with open(bbox_def_file) as f:\n",
    "        current_filename = None\n",
    "        bboxes_left_in_run = -1\n",
    "        current_bboxes = []\n",
    "        bboxes = []\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if line.isnumeric():\n",
    "                bbox_by_image[current_filename]['n_bboxes'] = int(line)\n",
    "            elif all(token.isnumeric() for token in line.split()):\n",
    "                x1, y1, w, h, *rest = line.split()\n",
    "                bbox = {\"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x1) + int(w), \"y2\": int(y1) + int(h)}\n",
    "                bboxes.append(bbox)\n",
    "            else:\n",
    "                if current_filename and bboxes:\n",
    "                    bbox_by_image[current_filename]['bboxes'] = bboxes\n",
    "                    bboxes = []\n",
    "                current_filename = line\n",
    "                bbox_by_image[current_filename] = {}\n",
    "\n",
    "    return bbox_by_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = list(img_files)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/work/data/object_detection/WIDER/WIDER_val/images/11--Meeting/11_Meeting_Meeting_11_Meeting_Meeting_11_663.jpg'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_key(file):\n",
    "    file_name = pathlib.Path(file).name\n",
    "    parent_dir = pathlib.Path(file).parent.name\n",
    "    return os.path.join(parent_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11--Meeting/11_Meeting_Meeting_11_Meeting_Meeting_11_663.jpg'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bbox = load_bbox_data(\"/Users/work/data/object_detection/WIDER/WIDER_val/wider_face_val_bbx_gt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3226"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(val_bbox.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3226"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/work/data/object_detection/WIDER/WIDER_val/wider_face_val_bbox_dict.json\", 'w') as f:\n",
    "    json.dump(val_bbox, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bbox = load_bbox_data(\"/Users/work/data/object_detection/WIDER/WIDER_train/wider_face_train_bbx_gt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12880"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_bbox.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/work/data/object_detection/WIDER/WIDER_train/wider_face_train_bbox_dict.json\", 'w') as f:\n",
    "    json.dump(train_bbox, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(image_filename, encoded_img, width, height, bboxes):\n",
    "  \"\"\"Creates a tf.Example proto for a given image.\n",
    "\n",
    "  Args:\n",
    "    encoded_img: The jpg encoded data of the image.\n",
    "\n",
    "  Returns:\n",
    "    example: The created tf.Example.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  image_format = b'jpg'\n",
    "\n",
    "  xmins = []\n",
    "  xmaxs = []\n",
    "  ymins = []\n",
    "  ymaxs = []\n",
    "  classes_text = []\n",
    "  classes = []\n",
    "\n",
    "  for bbox_data in bboxes:\n",
    "      # bbox coordinates are normalized\n",
    "      height = height\n",
    "      width = width\n",
    "      box_x1 = bbox_data['x1'] / width\n",
    "      box_x2 = bbox_data['x2'] / width\n",
    "      box_y1 = bbox_data['y1'] / height\n",
    "      box_y2 = bbox_data['y2'] / height\n",
    "      if box_x1 < 0 or box_x2 > 1.0 or box_y1 < 0 or box_y2 > 1.0:\n",
    "        continue\n",
    "\n",
    "      xmins.append(box_x1)\n",
    "      xmaxs.append(box_x2)\n",
    "      ymins.append(box_y1)\n",
    "      ymaxs.append(box_y2)\n",
    "      classes_text.append(b'face')\n",
    "      classes.append(1)\n",
    "\n",
    "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': int64_feature(height),\n",
    "      'image/width': int64_feature(width),\n",
    "      'image/filename': bytes_feature(bytes(image_filename, encoding='utf-8')),\n",
    "      'image/source_id': bytes_feature(bytes(image_filename, encoding='utf-8')),\n",
    "      'image/encoded': bytes_feature(encoded_img),\n",
    "      'image/format': bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "      'image/object/class/text': bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': int64_list_feature(classes),\n",
    "  }))\n",
    "  return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_filenames, bbox_by_image):\n",
    "    for image_file in image_filenames:\n",
    "        encoded_img, width, height = load_image(image_file)\n",
    "        file_key = get_file_key(image_file)\n",
    "        try:\n",
    "            yield create_tf_example(image_file, encoded_img, width, height, bbox_by_image[file_key]['bboxes'])\n",
    "#             for bbox in bbox_by_image[file_key]['bboxes']:\n",
    "#                 try:\n",
    "#                     yield create_tf_example(image_file, encoded_img, bbox)\n",
    "#                 except ZeroDivisionError:\n",
    "#                     pass\n",
    "        except (KeyError, ZeroDivisionError):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = list(create_dataset(val_img_files, val_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3225"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bboxes': [{'x1': 131, 'x2': 164, 'y1': 187, 'y2': 230},\n",
       "  {'x1': 243, 'x2': 276, 'y1': 214, 'y2': 261},\n",
       "  {'x1': 363, 'x2': 402, 'y1': 204, 'y2': 247},\n",
       "  {'x1': 481, 'x2': 525, 'y1': 156, 'y2': 215},\n",
       "  {'x1': 584, 'x2': 608, 'y1': 200, 'y2': 239},\n",
       "  {'x1': 641, 'x2': 691, 'y1': 165, 'y2': 223},\n",
       "  {'x1': 728, 'x2': 761, 'y1': 177, 'y2': 224},\n",
       "  {'x1': 760, 'x2': 814, 'y1': 128, 'y2': 201},\n",
       "  {'x1': 989, 'x2': 1022, 'y1': 188, 'y2': 246},\n",
       "  {'x1': 105, 'x2': 131, 'y1': 243, 'y2': 272}],\n",
       " 'n_bboxes': 10}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_bbox.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset(tf_examples, output_path):\n",
    "  writer = tf.python_io.TFRecordWriter(output_path)\n",
    "\n",
    "  for tf_example in tf_examples:\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataset(val_dataset, \"/Users/work/data/object_detection/WIDER/WIDER_val/WIDER_val.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = list(create_dataset(train_img_files, train_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataset(train_dataset, \"/Users/work/data/object_detection/WIDER/WIDER_train/WIDER_train.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12879"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
