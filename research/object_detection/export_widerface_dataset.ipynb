{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/share/virtualenvs/tensorflow_models-cADKlZN6/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/david/.local/share/virtualenvs/tensorflow_models-cADKlZN6/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/david/.local/share/virtualenvs/tensorflow_models-cADKlZN6/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/david/.local/share/virtualenvs/tensorflow_models-cADKlZN6/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/david/.local/share/virtualenvs/tensorflow_models-cADKlZN6/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/david/.local/share/virtualenvs/tensorflow_models-cADKlZN6/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Change these paths\n",
    "VAL_IMG_PATH = os.path.join(\"/media/david/e021a7c1-e806-43d8-af8c-531486336fba/data/face_detection/WIDER_val/images\", '*', '*.jpg')\n",
    "TRAIN_IMG_PATH = os.path.join(\"/media/david/e021a7c1-e806-43d8-af8c-531486336fba/data/face_detection/WIDER_train/images\", '*', '*.jpg')\n",
    "\n",
    "def int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(image_path):\n",
    "    for img_filename in glob(image_path):\n",
    "        yield img_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_files = list(get_images(VAL_IMG_PATH))\n",
    "train_img_files = list(get_images(TRAIN_IMG_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    img = Image.open(filename)\n",
    "    width = img.width\n",
    "    height = img.height\n",
    "    with open(filename, 'rb') as f:\n",
    "        return f.read(), width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12880"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3226"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bbox_data(bbox_def_file):\n",
    "    bbox_by_image = {}\n",
    "    with open(bbox_def_file) as f:\n",
    "        current_filename = None\n",
    "        bboxes_left_in_run = -1\n",
    "        current_bboxes = []\n",
    "        bboxes = []\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if line.isnumeric():\n",
    "                bbox_by_image[current_filename]['n_bboxes'] = int(line)\n",
    "            elif all(token.isnumeric() for token in line.split()):\n",
    "                x1, y1, w, h, *rest = line.split()\n",
    "                bbox = {\"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x1) + int(w), \"y2\": int(y1) + int(h)}\n",
    "                bboxes.append(bbox)\n",
    "            else:\n",
    "                if current_filename and bboxes:\n",
    "                    bbox_by_image[current_filename]['bboxes'] = bboxes\n",
    "                    bboxes = []\n",
    "                current_filename = line\n",
    "                bbox_by_image[current_filename] = {}\n",
    "\n",
    "    return bbox_by_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset has detections keyed by the a relative file path, but we have\n",
    "# absolute paths, so convert those abs paths to the required keys\n",
    "def get_file_key(file):\n",
    "    file_name = pathlib.Path(file).name\n",
    "    parent_dir = pathlib.Path(file).parent.name\n",
    "    return os.path.join(parent_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bbox = load_bbox_data(\"/media/david/e021a7c1-e806-43d8-af8c-531486336fba/data/face_detection/WIDER_val/wider_face_val_bbx_gt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3226"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(val_bbox.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bbox = load_bbox_data(\"/media/david/e021a7c1-e806-43d8-af8c-531486336fba/data/face_detection/WIDER_train/wider_face_train_bbx_gt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12880"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_bbox.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(image_filename, encoded_img, width, height, bboxes):\n",
    "  \"\"\"Creates a tf.Example proto for a given image.\n",
    "\n",
    "  Args:\n",
    "    encoded_img: The jpg encoded data of the image.\n",
    "\n",
    "  Returns:\n",
    "    example: The created tf.Example.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  image_format = b'jpg'\n",
    "\n",
    "  xmins = []\n",
    "  xmaxs = []\n",
    "  ymins = []\n",
    "  ymaxs = []\n",
    "  classes_text = []\n",
    "  classes = []\n",
    "\n",
    "  for bbox_data in bboxes:\n",
    "      # bbox coordinates are normalized\n",
    "      height = height\n",
    "      width = width\n",
    "      box_x1 = bbox_data['x1'] / width\n",
    "      box_x2 = bbox_data['x2'] / width\n",
    "      box_y1 = bbox_data['y1'] / height\n",
    "      box_y2 = bbox_data['y2'] / height\n",
    "      if box_x1 < 0 or box_x2 > 1.0 or box_y1 < 0 or box_y2 > 1.0:\n",
    "        continue\n",
    "\n",
    "      xmins.append(box_x1)\n",
    "      xmaxs.append(box_x2)\n",
    "      ymins.append(box_y1)\n",
    "      ymaxs.append(box_y2)\n",
    "      classes_text.append(b'face')\n",
    "      classes.append(1)\n",
    "\n",
    "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': int64_feature(height),\n",
    "      'image/width': int64_feature(width),\n",
    "      'image/filename': bytes_feature(bytes(image_filename, encoding='utf-8')),\n",
    "      'image/source_id': bytes_feature(bytes(image_filename, encoding='utf-8')),\n",
    "      'image/encoded': bytes_feature(encoded_img),\n",
    "      'image/format': bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "      'image/object/class/text': bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': int64_list_feature(classes),\n",
    "  }))\n",
    "  return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_filenames, bbox_by_image):\n",
    "    for image_file in image_filenames:\n",
    "        encoded_img, width, height = load_image(image_file)\n",
    "        file_key = get_file_key(image_file)\n",
    "        try:\n",
    "            yield create_tf_example(image_file, encoded_img, width, height, bbox_by_image[file_key]['bboxes'])\n",
    "\n",
    "        except (KeyError, ZeroDivisionError):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = list(create_dataset(val_img_files, val_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bboxes': [{'x1': 146, 'x2': 284, 'y1': 134, 'y2': 250},\n",
       "  {'x1': 398, 'x2': 526, 'y1': 68, 'y2': 224},\n",
       "  {'x1': 614, 'x2': 744, 'y1': 104, 'y2': 314}],\n",
       " 'n_bboxes': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_bbox.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset(tf_examples, output_path):\n",
    "  writer = tf.python_io.TFRecordWriter(output_path)\n",
    "\n",
    "  for tf_example in tf_examples:\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataset(val_dataset, \"/media/david/e021a7c1-e806-43d8-af8c-531486336fba/data/face_detection/WIDER_val/WIDER_val2.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = list(create_dataset(train_img_files, train_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataset(train_dataset, \"/media/david/e021a7c1-e806-43d8-af8c-531486336fba/data/face_detection/WIDER_train/WIDER_train2.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12879"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
